{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"266_test_original_model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPuTqYhdzUPxAzevNgON/ZE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"81SA4ILCy8zo"},"source":["!pip install -r requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oHH-YLsX0-Mw"},"source":["!python 'interact.py'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ClpxOEQfOWjU"},"source":["import pandas as pd\n","seinfeld_df = pd.read_json(\"seinfeld_data.json\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-APyzglLOn5g"},"source":["breakfast_club_json = breakfast_club_df.to_json(orient=\"records\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"91pbp_fwVICJ"},"source":["import json\n","with open(\"./seinfeld_data.json\", \"r\", encoding=\"utf-8\") as f:\n","    dataset = json.loads(f.read())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z1D1DPTLVV5G","executionInfo":{"status":"ok","timestamp":1616909880867,"user_tz":420,"elapsed":214,"user":{"displayName":"Inderpal Kaur","photoUrl":"","userId":"14511468679195080108"}},"outputId":"bd83a676-bff6-437d-fd06-89397b6686ea"},"source":["dataset['valid'][0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'personality': ['my name is george costanza .',\n","  'i have numerous psychological problems .',\n","  'i am bitter, miserly, selfish, greedy, and dishonest .',\n","  'i am very good at lying .',\n","  'i grew up with a difficult family life .',\n","  'i have a fear of commitment and marriage.'],\n"," 'utterances': [{'candidates': [' are you kidding ? lincoln center . alice tully hall, the met . magnificent facilities . ',\n","    \" alright, you boys get yourselves together . we'll head up to the restaurant . i'll leave a note for elaine . i'm going to the bathroom . \",\n","    \" tan pants . why do i buy tan pants, donna ? i don't feel comfortable in them .\",\n","    'i like to strain the sauce .',\n","    'hey, hey, are you a cop ?',\n","    \"i'm not moving in .\",\n","    \"you're going by 48th st . you can give me a ride .\",\n","    \"you can't win . you can't beat me . that's why i'm here and you're there . because i'm a winner . i'll always be a winner and you'll always be a loser .\",\n","    \"i'm sure it's right around here .\",\n","    '\"had to come in\" and \"maybe we\\'ll get together\" ? \"had to\" and \"maybe\" ?',\n","    'holistic . . that sounds right .',\n","    'and then, then, then she leaves with somebody else ! never even, never even said goodbye ! never called me back . . never apologized . nothing . like i was dirt .',\n","    \"what do you want me to do ? i gave the guy the half-turn . then i have him the full-turn with the eye roll ! i mean, beyond that, i'm risking a punch in the mouth . .  excuse me, do you have these in the puffs ?\",\n","    'excuse me, do you have these in the puffs ?',\n","    \"no, i think i saw him on land a couple times . so how's the job situation goin' ?\",\n","    \" i don't know how this happened .\",\n","    \"no .  so now you're going to his apartment ? i really think this is nuts .\",\n","    'no kidding   why is this happening ? please, make her stop !',\n","    'well, is it good ?',\n","    'oh, yeah, sure, accident, right . she was aiming right at me like she was putting out a fire ! then, for the rest of the show, i\\'m sitting there with chocolate all over my shirt . flies are landing on me . i\\'m boiling - i\\'m fantasizing all the things i\\'m gonna say when i see her . and later, finally, backstage when i talk to her, i\\'m a groveling worm . \"what kind of chocolate was that ? do you throw any other foods ?\"'],\n","   'history': ['it was an accident !']}]}"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"kX1VUAq6POfj"},"source":["print(json.dumps(json.loads(breakfast_club_json)[0], indent=2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F3JvnWS5Rv8q","executionInfo":{"status":"ok","timestamp":1617038945827,"user_tz":420,"elapsed":1254113,"user":{"displayName":"Inderpal Kaur","photoUrl":"","userId":"14511468679195080108"}},"outputId":"88817b0a-966c-4908-fd80-c1a0af2a82db"},"source":["!python ./train.py --dataset_path \"./seinfeld_data-3.json\""],"execution_count":2,"outputs":[{"output_type":"stream","text":["2021-03-29 17:08:16.783806: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","WARNING:./train.py:Running process -1\n","INFO:./train.py:Arguments: Namespace(dataset_cache='./dataset_cache', dataset_path='./seinfeld_data-3.json', device='cuda', eval_before_start=False, fp16='', gradient_accumulation_steps=8, lm_coef=1.0, local_rank=-1, lr=6.25e-05, max_history=2, max_norm=1.0, mc_coef=1.0, model_checkpoint='openai-gpt', n_epochs=3, num_candidates=2, personality_permutations=1, train_batch_size=4, valid_batch_size=4)\n","INFO:./train.py:Prepare tokenizer, pretrained model and optimizer.\n","INFO:filelock:Lock 140244922055504 acquired on /root/.cache/torch/transformers/4ab93d0cd78ae80e746c27c9cd34e90b470abdabe0590c9ec742df61625ba310.b9628f6fe5519626534b82ce7ec72b22ce0ae79550325f45c604a25c0ad87fd6.lock\n","INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-vocab.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp9dpvfif3\n","Downloading: 100% 816k/816k [00:01<00:00, 734kB/s] \n","INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-vocab.json in cache at /root/.cache/torch/transformers/4ab93d0cd78ae80e746c27c9cd34e90b470abdabe0590c9ec742df61625ba310.b9628f6fe5519626534b82ce7ec72b22ce0ae79550325f45c604a25c0ad87fd6\n","INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/4ab93d0cd78ae80e746c27c9cd34e90b470abdabe0590c9ec742df61625ba310.b9628f6fe5519626534b82ce7ec72b22ce0ae79550325f45c604a25c0ad87fd6\n","INFO:filelock:Lock 140244922055504 released on /root/.cache/torch/transformers/4ab93d0cd78ae80e746c27c9cd34e90b470abdabe0590c9ec742df61625ba310.b9628f6fe5519626534b82ce7ec72b22ce0ae79550325f45c604a25c0ad87fd6.lock\n","INFO:filelock:Lock 140244922550288 acquired on /root/.cache/torch/transformers/0f8de0dbd6a2bb6bde7d758f4c120dd6dd20b46f2bf0a47bc899c89f46532fde.20808570f9a3169212a577f819c845330da870aeb14c40f7319819fce10c3b76.lock\n","INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-merges.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmphie6dpb2\n","Downloading: 100% 458k/458k [00:00<00:00, 512kB/s] \n","INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-merges.txt in cache at /root/.cache/torch/transformers/0f8de0dbd6a2bb6bde7d758f4c120dd6dd20b46f2bf0a47bc899c89f46532fde.20808570f9a3169212a577f819c845330da870aeb14c40f7319819fce10c3b76\n","INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/0f8de0dbd6a2bb6bde7d758f4c120dd6dd20b46f2bf0a47bc899c89f46532fde.20808570f9a3169212a577f819c845330da870aeb14c40f7319819fce10c3b76\n","INFO:filelock:Lock 140244922550288 released on /root/.cache/torch/transformers/0f8de0dbd6a2bb6bde7d758f4c120dd6dd20b46f2bf0a47bc899c89f46532fde.20808570f9a3169212a577f819c845330da870aeb14c40f7319819fce10c3b76.lock\n","INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-vocab.json from cache at /root/.cache/torch/transformers/4ab93d0cd78ae80e746c27c9cd34e90b470abdabe0590c9ec742df61625ba310.b9628f6fe5519626534b82ce7ec72b22ce0ae79550325f45c604a25c0ad87fd6\n","INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-merges.txt from cache at /root/.cache/torch/transformers/0f8de0dbd6a2bb6bde7d758f4c120dd6dd20b46f2bf0a47bc899c89f46532fde.20808570f9a3169212a577f819c845330da870aeb14c40f7319819fce10c3b76\n","WARNING:transformers.tokenization_openai:ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n","INFO:filelock:Lock 140244867982736 acquired on /root/.cache/torch/transformers/a27bb7c70e9002d7558d2682d5a95f3c0a8b31034616309459e0b51ef07ade09.bd0797be126548711309ad2174d2afb16e3c37e891707667603d85e35a4ad001.lock\n","INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpu5u0xjlk\n","Downloading: 100% 656/656 [00:00<00:00, 479kB/s]\n","INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-config.json in cache at /root/.cache/torch/transformers/a27bb7c70e9002d7558d2682d5a95f3c0a8b31034616309459e0b51ef07ade09.bd0797be126548711309ad2174d2afb16e3c37e891707667603d85e35a4ad001\n","INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/a27bb7c70e9002d7558d2682d5a95f3c0a8b31034616309459e0b51ef07ade09.bd0797be126548711309ad2174d2afb16e3c37e891707667603d85e35a4ad001\n","INFO:filelock:Lock 140244867982736 released on /root/.cache/torch/transformers/a27bb7c70e9002d7558d2682d5a95f3c0a8b31034616309459e0b51ef07ade09.bd0797be126548711309ad2174d2afb16e3c37e891707667603d85e35a4ad001.lock\n","INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-config.json from cache at /root/.cache/torch/transformers/a27bb7c70e9002d7558d2682d5a95f3c0a8b31034616309459e0b51ef07ade09.bd0797be126548711309ad2174d2afb16e3c37e891707667603d85e35a4ad001\n","INFO:transformers.configuration_utils:Model config OpenAIGPTConfig {\n","  \"afn\": \"gelu\",\n","  \"architectures\": [\n","    \"OpenAIGPTLMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": null,\n","  \"do_sample\": false,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_ids\": null,\n","  \"finetuning_task\": null,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"is_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"model_type\": \"openai-gpt\",\n","  \"n_ctx\": 512,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 512,\n","  \"n_special\": 0,\n","  \"num_beams\": 1,\n","  \"num_labels\": 2,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": null,\n","  \"predict_special_tokens\": true,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 40478\n","}\n","\n","INFO:filelock:Lock 140244867982416 acquired on /root/.cache/torch/transformers/e45ee1afb14c5d77c946e66cb0fa70073a77882097a1a2cefd51fd24b172355e.e7ee3fcd07c695a4c9f31ca735502c090230d988de03202f7af9ebe1c3a4054c.lock\n","INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmppatsa97t\n","Downloading: 100% 479M/479M [00:40<00:00, 11.9MB/s]\n","INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-pytorch_model.bin in cache at /root/.cache/torch/transformers/e45ee1afb14c5d77c946e66cb0fa70073a77882097a1a2cefd51fd24b172355e.e7ee3fcd07c695a4c9f31ca735502c090230d988de03202f7af9ebe1c3a4054c\n","INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/e45ee1afb14c5d77c946e66cb0fa70073a77882097a1a2cefd51fd24b172355e.e7ee3fcd07c695a4c9f31ca735502c090230d988de03202f7af9ebe1c3a4054c\n","INFO:filelock:Lock 140244867982416 released on /root/.cache/torch/transformers/e45ee1afb14c5d77c946e66cb0fa70073a77882097a1a2cefd51fd24b172355e.e7ee3fcd07c695a4c9f31ca735502c090230d988de03202f7af9ebe1c3a4054c.lock\n","INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-pytorch_model.bin from cache at /root/.cache/torch/transformers/e45ee1afb14c5d77c946e66cb0fa70073a77882097a1a2cefd51fd24b172355e.e7ee3fcd07c695a4c9f31ca735502c090230d988de03202f7af9ebe1c3a4054c\n","INFO:transformers.tokenization_utils:Adding <bos> to the vocabulary\n","INFO:transformers.tokenization_utils:Assigning <bos> to the bos_token key of the tokenizer\n","INFO:transformers.tokenization_utils:Adding <eos> to the vocabulary\n","INFO:transformers.tokenization_utils:Assigning <eos> to the eos_token key of the tokenizer\n","INFO:transformers.tokenization_utils:Adding <pad> to the vocabulary\n","INFO:transformers.tokenization_utils:Assigning <pad> to the pad_token key of the tokenizer\n","INFO:transformers.tokenization_utils:Adding <speaker1> to the vocabulary\n","INFO:transformers.tokenization_utils:Adding <speaker2> to the vocabulary\n","INFO:transformers.tokenization_utils:Assigning ['<speaker1>', '<speaker2>'] to the additional_special_tokens key of the tokenizer\n","INFO:./train.py:Prepare datasets\n","INFO:/content/utils.py:Download dataset from ./seinfeld_data-3.json\n","INFO:/content/utils.py:Tokenize and encode the dataset\n","INFO:./train.py:Build inputs and labels\n","INFO:./train.py:Pad inputs and convert to Tensor\n","INFO:./train.py:Build train and validation dataloaders\n","INFO:./train.py:Train dataset (Batch, Candidates, Seq length): torch.Size([3157, 2, 371])\n","INFO:./train.py:Valid dataset (Batch, Candidates, Seq length): torch.Size([327, 20, 384])\n","/usr/local/lib/python3.7/dist-packages/ignite/handlers/checkpoint.py:830: UserWarning: Argument save_interval is deprecated and should be None. This argument will be removed in 0.5.0.Please, use events filtering instead, e.g. Events.ITERATION_STARTED(every=1000)\n","  warnings.warn(msg)\n","INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=3.\n","Epoch [1/3]:   1% 7/790 [00:08<18:23,  1.41s/it, loss=0.826]/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","Epoch [1/3]: 100% 790/790 [19:09<00:00,  1.14s/it, loss=0.434]INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n","INFO:./train.py:<bos> my name is george costanza. i have numerous psychological problems. i am bitter, miserly, selfish, greedy, and dishonest. i am very good at lying. i grew up with a difficult family life. i have a fear of commitment and marriage. <speaker2> hello, rick. <speaker1> heh heh heh hey! look who's here! <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n","ERROR:ignite.engine.engine.Engine:Current run is terminating due to exception: CUDA out of memory. Tried to allocate 4.62 GiB (GPU 0; 11.17 GiB total capacity; 6.40 GiB already allocated; 3.97 GiB free; 6.77 GiB reserved in total by PyTorch)\n","ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: CUDA out of memory. Tried to allocate 4.62 GiB (GPU 0; 11.17 GiB total capacity; 6.40 GiB already allocated; 3.97 GiB free; 6.77 GiB reserved in total by PyTorch)\n","ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: CUDA out of memory. Tried to allocate 4.62 GiB (GPU 0; 11.17 GiB total capacity; 6.40 GiB already allocated; 3.97 GiB free; 6.77 GiB reserved in total by PyTorch)\n","Traceback (most recent call last):\n","  File \"./train.py\", line 267, in <module>\n","    train()\n","  File \"./train.py\", line 259, in train\n","    trainer.run(train_loader, max_epochs=args.n_epochs)\n","  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 702, in run\n","    return self._internal_run()\n","  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 775, in _internal_run\n","    self._handle_exception(e)\n","  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 469, in _handle_exception\n","    raise e\n","  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 752, in _internal_run\n","    self._fire_event(Events.EPOCH_COMPLETED)\n","  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 424, in _fire_event\n","    func(*first, *(event_args + others), **kwargs)\n","  File \"./train.py\", line 213, in <lambda>\n","    trainer.add_event_handler(Events.EPOCH_COMPLETED, lambda _: evaluator.run(val_loader))\n","  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 702, in run\n","    return self._internal_run()\n","  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 775, in _internal_run\n","    self._handle_exception(e)\n","  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 469, in _handle_exception\n","    raise e\n","  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 745, in _internal_run\n","    time_taken = self._run_once_on_dataset()\n","  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 850, in _run_once_on_dataset\n","    self._handle_exception(e)\n","  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 469, in _handle_exception\n","    raise e\n","  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 833, in _run_once_on_dataset\n","    self.state.output = self._process_function(self, self.state.batch)\n","  File \"./train.py\", line 207, in inference\n","    lm_logits_flat_shifted = lm_logits[..., :-1, :].contiguous().view(-1, lm_logits.size(-1))\n","RuntimeError: CUDA out of memory. Tried to allocate 4.62 GiB (GPU 0; 11.17 GiB total capacity; 6.40 GiB already allocated; 3.97 GiB free; 6.77 GiB reserved in total by PyTorch)\n","Epoch [1/3]: 100% 790/790 [19:15<00:00,  1.46s/it, loss=0.434]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FCPxKp0TQAST","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616810986144,"user_tz":420,"elapsed":376973,"user":{"displayName":"Inderpal Kaur","photoUrl":"","userId":"14511468679195080108"}},"outputId":"031ce6f5-d41c-4b5f-952c-041df1f051ad"},"source":["!python ./interact.py --model_checkpoint ./runs/Mar27_01-55-15_9dea942f935b_openai-gpt/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-03-27 02:03:30.408179: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","INFO:./interact.py:Namespace(dataset_cache='./dataset_cache', dataset_path='', device='cuda', max_history=2, max_length=20, min_length=1, model='openai-gpt', model_checkpoint='./runs/Mar27_01-55-15_9dea942f935b_openai-gpt/', no_sample=False, seed=0, temperature=0.7, top_k=0, top_p=0.9)\n","INFO:./interact.py:Get pretrained model and tokenizer\n","INFO:transformers.tokenization_utils:Model name './runs/Mar27_01-55-15_9dea942f935b_openai-gpt/' not found in model shortcut name list (openai-gpt). Assuming './runs/Mar27_01-55-15_9dea942f935b_openai-gpt/' is a path, a model identifier, or url to a directory containing tokenizer files.\n","INFO:transformers.tokenization_utils:loading file ./runs/Mar27_01-55-15_9dea942f935b_openai-gpt/vocab.json\n","INFO:transformers.tokenization_utils:loading file ./runs/Mar27_01-55-15_9dea942f935b_openai-gpt/merges.txt\n","INFO:transformers.tokenization_utils:loading file ./runs/Mar27_01-55-15_9dea942f935b_openai-gpt/added_tokens.json\n","INFO:transformers.tokenization_utils:loading file ./runs/Mar27_01-55-15_9dea942f935b_openai-gpt/special_tokens_map.json\n","INFO:transformers.tokenization_utils:loading file ./runs/Mar27_01-55-15_9dea942f935b_openai-gpt/tokenizer_config.json\n","WARNING:transformers.tokenization_openai:ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n","INFO:transformers.configuration_utils:loading configuration file ./runs/Mar27_01-55-15_9dea942f935b_openai-gpt/config.json\n","INFO:transformers.configuration_utils:Model config OpenAIGPTConfig {\n","  \"afn\": \"gelu\",\n","  \"architectures\": [\n","    \"OpenAIGPTLMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": null,\n","  \"do_sample\": false,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_ids\": null,\n","  \"finetuning_task\": null,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"is_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"model_type\": \"openai-gpt\",\n","  \"n_ctx\": 512,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 512,\n","  \"n_special\": 0,\n","  \"num_beams\": 1,\n","  \"num_labels\": 1,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": null,\n","  \"predict_special_tokens\": true,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 40483\n","}\n","\n","INFO:transformers.modeling_utils:loading weights file ./runs/Mar27_01-55-15_9dea942f935b_openai-gpt/pytorch_model.bin\n","INFO:transformers.modeling_utils:Weights from pretrained model not used in OpenAIGPTLMHeadModel: ['multiple_choice_head.summary.weight', 'multiple_choice_head.summary.bias']\n","INFO:transformers.tokenization_utils:Assigning <bos> to the bos_token key of the tokenizer\n","INFO:transformers.tokenization_utils:Assigning <eos> to the eos_token key of the tokenizer\n","INFO:transformers.tokenization_utils:Assigning <pad> to the pad_token key of the tokenizer\n","INFO:transformers.tokenization_utils:Assigning ['<speaker1>', '<speaker2>'] to the additional_special_tokens key of the tokenizer\n","INFO:./interact.py:Sample a personality\n","INFO:/content/utils.py:Load tokenized dataset from cache at ./dataset_cache_OpenAIGPTTokenizer\n","INFO:./interact.py:Selected personality: my name is john bender. i take pleasure in making other people uncomfortable. i don't like authority. i have an abusive home life. i pulled a false fire alarm. i talk back to teachers.\n",">>> hi\n","my name is john bender and i don't like authority. i was kidnapped and i know who you\n",">>> what do you like to do?\n","i am an art student at nyu. i study art history and i write to art students,\n",">>> what do you think about authority?\n","i think you need it.\n",">>> what is your name?\n","i am john bender and i would like to say that i am a student of art history but i\n",">>> what do you do on saturdays?\n","i don't have saturdays. i go to work on saturday mornings. i don't work saturdays on\n",">>> how is your father?\n","i hope you are not a teacher. i know i am not. he is a teacher. i\n",">>> do you like Claire?\n","you have a good teacher? \n"," yes, i think so.\n",">>> Traceback (most recent call last):\n","  File \"./interact.py\", line 154, in <module>\n","    run()\n","  File \"./interact.py\", line 140, in run\n","    raw_text = input(\">>> \")\n","KeyboardInterrupt\n","^C\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_R4aZWKAbAnO"},"source":[""],"execution_count":null,"outputs":[]}]}